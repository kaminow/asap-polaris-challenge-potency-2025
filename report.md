**This is still a work in progress and is incomplete**
***

# Intro/Disclaimers

This submission is largely meant as a proof-of-concept/showcase for the
(`asapdiscovery`)[https://github.com/asapdiscovery/asapdiscovery/] and
(`mtenn`)[https://github.com/choderalab/mtenn/] frameworks developed by myself and
others in the Chodera Lab and ASAP Discovery Consortium. **Importantly, all code and
data used in this project are publicly accessible. Nothing propietary or confidential
was used, and all results should be replicable by anyone coming across this repo.**

All figures used in this report live in the `figures/` directory and were generated by
various Jupyter notebooks in the `notebooks/` directory. The notebooks are bit
disorganized, but should recreate all the relevant figures if you run them.

# Setup

Installation and setup for `asapdiscovery` and `mtenn` can be found in their respective
documentation. I used development branch versions of both packages (commit
(`d5f686a`)[https://github.com/asapdiscovery/asapdiscovery/commit/d5f686a] in the
`add-weight-decay-loss` branch for `asapdiscovery` and commit
(`09564fb`)[https://github.com/choderalab/mtenn/commit/09564fb] in the
`add-label-strategy` branch for `mtenn`), so these will unfortunately need to be
installed manually rather than using the `conda-forge` packages. Those may work, but I
haven't done any testing with them for this project.

# Data Acquisition

I opted to work from the raw data package, mainly because I wanted to utilize the date
property in order to train using a temporal split. The data can be downloaded from
(this page)[https://polarishub.io/datasets/asap-discovery/antiviral-potency-2025-sample]
or using the following command.

```bash
wget https://fs.polarishub.io/2025-01-asap-discovery/raw_data_package.zip
```

## Extract data and set up directories

We'll unzip the data into its own directory and make a new directory for our parse
datasets:

```bash
mkdir raw_data
mv raw_data_package.zip raw_data/
cd raw_data/
unzip raw_data/raw_data_package.zip
cd ..
mkdir parsed_datasets
```

## Parse the competition training data

We next need to parse these raw CSV files into the format that the `asapdiscovery-ml`
CLI expects. For more information on these formats, please see the
(relevant docs page)
[https://asapdiscovery.readthedocs.io/en/latest/guides/using_ml_cli.html].

Before running the standard CLI, there is one ad hoc processing script that I had to
write because the data to use for the MERS data are the Minh columns, which are in a
slightly different naming format than expected. After that, the process is mostly
identical for both the SARS and MERS data:

```bash
# Rename the necessary columns
python scripts/parse_minh_values.py

# Parse the CSV files and convert them into the format expected by the ML CLI
asap-cli data download-cdd \
--cache raw_data/SARS-CoV-2-Mpro_potencies_CONFIDENTIAL.csv \
--output parsed_datasets/sars_parsed.csv \
--smiles-fieldname "CXSMILES (CDD Compatible)" \
--id-fieldname "Molecule Name" \
--retain-all \
--assay-name "SARS-CoV-2-MPro_fluorescence-dose-response_weizmann" \
--cheng-prusoff 0,0
asap-cli data cdd-to-schema \
--in-file parsed_datasets/sars_parsed.csv \
--out-json parsed_datasets/sars_exp_file.json

asap-cli data download-cdd \
--cache raw_data/MERS-CoV-Mpro_potencies_CONFIDENTIAL_minh_assay_fixed.csv \
--output parsed_datasets/mers_parsed.csv \
--smiles-fieldname "CXSMILES (CDD Compatible)" \
--id-fieldname "Molecule Name" \
--retain-all \
--assay-name "MERS-CoV-MPro_fluorescence-dose-response_weizmann_minh" \
--cheng-prusoff 0,0
asap-cli data cdd-to-schema \
--in-file parsed_datasets/mers_parsed.csv \
--out-json parsed_datasets/mers_exp_file.json

# Build the ML datasets and cache them
asap-ml build-dataset gat \
--exp-file parsed_datasets/sars_exp_file.json \
--ds-config-cache parsed_datasets/sars_gat_config.json \
--ds-cache parsed_datasets/sars_gat_ds.pkl
asap-ml build-dataset gat \
--exp-file parsed_datasets/mers_exp_file.json \
--ds-config-cache parsed_datasets/mers_gat_config.json \
--ds-cache parsed_datasets/mers_gat_ds.pkl
```

## Download and parse the pretraining data

I also experimented with pretraining models on the publicly available data from the
COVID Moonshot project, which can be downloaded and parsed fully using the
`asapdiscovery` package. Based on the intuition that the graph model I'm using has no
notion of stereochemistry, I only pretrained on the data for which stereochemistry is
either unique or unspecified (achiral molecules and racemates). Additionally, I keep any
semiquantitative measurements, which are treated specially in the loss function (see
docs for more information).

```bash
mkdir raw_data/moonshot

asap-cli data download-cdd \
--cache raw_data/moonshot/cdd_noncovalent_dates_raw.csv \
--output parsed_datasets/moonshot_parsed.csv \
--retain-achiral \
--retain-racemic \
--retain-semiquant

asap-cli data cdd-to-schema \
--in-file parsed_datasets/moonshot_parsed.csv \
--out-json parsed_datasets/moonshot_exp_file.json

asap-ml build-dataset gat \
--exp-file parsed_datasets/moonshot_exp_file.json \
--ds-config-cache parsed_datasets/moonshot_gat_config.json \
--ds-cache parsed_datasets/moonshot_gat_ds.pkl
```
